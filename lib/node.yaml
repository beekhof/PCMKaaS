heat_template_version: 2013-05-23

description: Template that installs a node ready to be added to a cluster.

# It should be possible to take the offical RH image, define
# rh_subscription above and start using the 'packages' directive.
# However this does not work due to SSL and Cert issues.
#
# For now use CentOS with cloud-init installed

parameters:
  name:
    type: string
    label: Cluster node name
    description: Name of the cluster node
    default: node
  cluster_pass:
    type: string
    label: Cluster password
  image:
    type: string
    label: Image name or ID
    description: Image to be used for server. Please use an RHEL/CentOS 7 based image for now.
  flavor:
    type: string
    label: Flavor
    description: Type of instance (flavor) to be used on the compute instance.
    default: m1.small
  key:
    type: string
    label: Key name
    description: Name of key-pair to be installed on the compute instance.
    default: default
  public_network:
    type: string
    label: Private network name or ID
    description: Network to attach server to.
    default: private
  private_network:
    type: string
    label: Private network name or ID
    description: Network to attach server to.
    default: private
  security_group:
    type: string
    description: Public network security group

resources:
  signal_handle:
    type: "OS::Heat::SwiftSignalHandle"

  wait_on_server:
    type: OS::Heat::SwiftSignal
    properties:
      handle: {get_resource: signal_handle}
      count: 1
      timeout: 2000

  floating_ip:
    type: floating_ip.yaml
    properties:
      public_network: { get_param: public_network }
      private_network: { get_param: private_network }
      security_group: { get_param: security_group }

  cluster_instance:
    type: OS::Nova::Server
    properties:
      name: { get_param: name }
      image: { get_param: image }
      flavor: { get_param: flavor }
      key_name: { get_param: key }
      networks:
        - port: { get_attr: [floating_ip, port] }
      user_data_format: RAW
      user_data:
        str_replace:
          params:
            # Replace all occurances of "wc_notify" in the script with an
            # appropriate curl PUT request using the "curl_cli" attribute
            # of the SwiftSignalHandle resource
            wc_notify:   { get_attr: ['signal_handle', 'curl_cli'] }
            __clock__: 'pool.ntp.org'
            __pass__: { get_param: cluster_pass }
          template: |
            Content-Type: multipart/mixed; boundary="===============3343034662225461311=="
            MIME-Version: 1.0
            
            --===============3343034662225461311==
            MIME-Version: 1.0
            Content-Type: text/cloud-config; charset="us-ascii"
            Content-Transfer-Encoding: 7bit
            Content-Disposition: attachment; filename="cloud.config"

            #cloud-config
            # See http://cloudinit.readthedocs.io/en/latest/topics/examples.html
            # Useful debugging options:
            password: redhat
            chpasswd: {expire: False}
            ssh_pwauth: True

            #  package_upgrade: true
            packages:
              - ntp
              - pcs
              - pacemaker
              - resource-agents
            #  - fence-agents-all

            --===============3343034662225461311==
            MIME-Version: 1.0
            Content-Type: text/x-shellscript; charset="us-ascii"
            Content-Transfer-Encoding: 7bit
            Content-Disposition: attachment; filename="cloud.sh"
            
            #!/bin/sh -ex

            firewall-cmd --add-service=high-availability

            # Start pcsd and set a password so that a peer can connect and configure us
            echo __pass__ | passwd --stdin hacluster
            systemctl enable pcsd
            systemctl start pcsd
            
            # The cluster shouldn't need NTP configured, but without it the
            # network goes bye-bye when using DHCP
            echo "SYNC_HWCLOCK=yes" >> /etc/sysconfig/ntpdate

            systemctl enable ntpdate
            systemctl start ntpdate

            systemctl enable ntpd
            systemctl start ntpd
            
            # Assuming long running operation completed successfully, notify success signal
            wc_notify --data-binary '{"status": "SUCCESS", "data": "Script execution succeeded"}'

            # find /var/lib/cloud/ -type f -print -exec cat \{\} \;
            
            # Alternatively if operation fails a FAILURE with reason and data may be sent,
            # notify failure signal example below
            # wc_notify --data-binary '{"status": "FAILURE", "reason":"Operation failed due to xyz error", "data":"Script execution failed"}'
          
            --===============3343034662225461311==--

outputs:
  name:
    description: Name of the tiny instance.
    value: { get_attr: [cluster_instance, name] }
  ip:
    description: The IP address of the tiny instance.
    value: { get_attr: [cluster_instance, first_address] }
  public_ip:
    description: The public IP address of the tiny instance.
    value: { get_attr: [floating_ip, ip] }
